{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02cb3ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2853\n",
      "Epoch 2, Loss: 2.2182\n",
      "Epoch 3, Loss: 2.1520\n",
      "Epoch 4, Loss: 2.0869\n",
      "Epoch 5, Loss: 2.0226\n",
      "Test Accuracy: 53.99%\n",
      "\n",
      "Sample Predictions:\n",
      "Token: SOCCER          | True: O          | Predicted: O\n",
      "Token: -               | True: O          | Predicted: O\n",
      "Token: JAPAN           | True: B-LOC      | Predicted: I-MISC\n",
      "Token: GET             | True: O          | Predicted: O\n",
      "Token: LUCKY           | True: O          | Predicted: O\n",
      "Token: WIN             | True: O          | Predicted: O\n",
      "Token: ,               | True: O          | Predicted: O\n",
      "Token: CHINA           | True: B-PER      | Predicted: B-LOC\n",
      "Token: IN              | True: O          | Predicted: I-PER\n",
      "Token: SURPRISE        | True: O          | Predicted: I-MISC\n",
      "Token: DEFEAT          | True: O          | Predicted: O\n",
      "Token: .               | True: O          | Predicted: O\n",
      "Token: Nadim           | True: B-PER      | Predicted: O\n",
      "Token: Ladki           | True: I-PER      | Predicted: O\n",
      "Token: AL-AIN          | True: B-LOC      | Predicted: O\n",
      "Token: ,               | True: O          | Predicted: O\n",
      "Token: United          | True: B-LOC      | Predicted: O\n",
      "Token: Arab            | True: I-LOC      | Predicted: I-MISC\n",
      "Token: Emirates        | True: I-LOC      | Predicted: I-MISC\n",
      "Token: 1996-12-06      | True: O          | Predicted: O\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "# Parameters\n",
    "WINDOW_SIZE = 3\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "# Load dataset using Hugging Face datasets\n",
    "conll_dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "train_data = conll_dataset[\"train\"]\n",
    "test_data = conll_dataset[\"test\"]\n",
    "\n",
    "# Build vocabularies\n",
    "word_counter = Counter(word for example in train_data for word in example['tokens'])\n",
    "label_set = set(label for example in train_data for label in example['ner_tags'])\n",
    "\n",
    "word2idx = {word: idx + 2 for idx, word in enumerate(word_counter)}  # reserve 0 and 1\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "word2idx[\"<UNK>\"] = 1\n",
    "\n",
    "idx2label = conll_dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "label2idx = {label: idx for idx, label in enumerate(idx2label)}\n",
    "OUTPUT_DIM = len(label2idx)\n",
    "\n",
    "# Convert data to windowed format\n",
    "def prepare_window_data(dataset, word2idx, label2idx, window_size):\n",
    "    X, Y, original_tokens = [], [], []\n",
    "    pad = [word2idx[\"<PAD>\"]] * (window_size // 2)\n",
    "\n",
    "    for example in dataset:\n",
    "        tokens = example[\"tokens\"]\n",
    "        labels = example[\"ner_tags\"]\n",
    "        indexed_sentence = [word2idx.get(word, word2idx[\"<UNK>\"]) for word in tokens]\n",
    "        padded_sentence = pad + indexed_sentence + pad\n",
    "\n",
    "        for i in range(len(tokens)):\n",
    "            window = padded_sentence[i:i + window_size]\n",
    "            X.append(window)\n",
    "            Y.append(labels[i])\n",
    "            original_tokens.append((tokens[i], labels[i]))\n",
    "\n",
    "    return torch.tensor(X), torch.tensor(Y), original_tokens\n",
    "\n",
    "X_train, y_train, _ = prepare_window_data(train_data, word2idx, label2idx, WINDOW_SIZE)\n",
    "X_test, y_test, test_tokens = prepare_window_data(test_data, word2idx, label2idx, WINDOW_SIZE)\n",
    "\n",
    "# Define the model\n",
    "class WindowBasedNER(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, window_size, hidden_dim, output_dim):\n",
    "        super(WindowBasedNER, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim * window_size, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view(inputs.shape[0], -1)\n",
    "        hidden = self.relu(self.fc1(embeds))\n",
    "        out = self.fc2(hidden)\n",
    "        return out\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = WindowBasedNER(len(word2idx), EMBEDDING_DIM, WINDOW_SIZE, HIDDEN_DIM, OUTPUT_DIM)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train)\n",
    "    loss = loss_function(predictions, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation with detailed outputs\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    predicted_labels = torch.argmax(predictions, dim=1)\n",
    "    accuracy = (predicted_labels == y_test).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item() * 100:.2f}%\")\n",
    "\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    for i in range(20):\n",
    "        token, true_label_id = test_tokens[i]\n",
    "        pred_label_id = predicted_labels[i].item()\n",
    "        print(f\"Token: {token:15} | True: {idx2label[true_label_id]:10} | Predicted: {idx2label[pred_label_id]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e473791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Training Data:\n",
      "Tokens: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "Labels: ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
      "\n",
      "Tokens: ['Peter', 'Blackburn']\n",
      "Labels: ['B-PER', 'I-PER']\n",
      "\n",
      "Tokens: ['BRUSSELS', '1996-08-22']\n",
      "Labels: ['B-LOC', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a few training examples\n",
    "print(\"\\nSample Training Data:\")\n",
    "for i in range(3):\n",
    "    print(f\"Tokens: {train_data[i]['tokens']}\")\n",
    "    print(f\"Labels: {[conll_dataset['train'].features['ner_tags'].feature.names[l] for l in train_data[i]['ner_tags']]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ebdd6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14041, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2411e624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'tokens': ['Peter', 'Blackburn'],\n",
       " 'pos_tags': [22, 22],\n",
       " 'chunk_tags': [11, 12],\n",
       " 'ner_tags': [1, 2]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11e759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
